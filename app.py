import streamlit as st
import google.generativeai as genai
import os
import time

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(
    page_title="Há»‡ thá»‘ng ChuyÃªn gia Thuáº¿ AI",
    page_icon="âš–ï¸",
    layout="wide", # Äá»•i sang wide Ä‘á»ƒ hiá»ƒn thá»‹ Ä‘Æ°á»£c nhiá»u thÃ´ng tin hÆ¡n
    initial_sidebar_state="expanded" # Má»Ÿ sidebar Ä‘á»ƒ xem danh sÃ¡ch file
)

# CSS lÃ m Ä‘áº¹p
st.markdown("""
<style>
    .stChatMessage {border-radius: 15px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);}
    .main-header {text-align: center; font-size: 28px; font-weight: 800; color: #1E88E5; margin-bottom: 10px;}
</style>
""", unsafe_allow_html=True)

# --- 2. HÃ€M Há»† THá»NG ---

def get_api_key():
    # Thá»­ láº¥y tá»« Secrets (Æ¯u tiÃªn Cloud/Web)
    if "GOOGLE_API_KEY" in st.secrets:
        return st.secrets["GOOGLE_API_KEY"]
    # Thá»­ láº¥y tá»« File local (MÃ¡y tÃ­nh)
    try:
        import toml
        secrets = toml.load(".streamlit/secrets.toml")
        return secrets["GOOGLE_API_KEY"]
    except:
        return None

def get_local_pdf_files(folder_path="tailieu"):
    if not os.path.exists(folder_path):
        return []
    return [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]

# ğŸ”¥ CACHE RESOURCE: Náº¡p dá»¯ liá»‡u
@st.cache_resource(show_spinner="Äang khá»Ÿi táº¡o há»‡ tri thá»©c Thuáº¿...")
def initialize_knowledge_base(_api_key):
    genai.configure(api_key=_api_key)
    
    local_files = get_local_pdf_files()
    if not local_files:
        return None, "âš ï¸ ThÆ° má»¥c 'tailieu' Ä‘ang trá»‘ng."

    uploaded_refs = []
    
    # Láº¥y danh sÃ¡ch file Ä‘Ã£ cÃ³ trÃªn Cloud
    try:
        existing_files = {f.display_name: f for f in genai.list_files()}
    except:
        existing_files = {}

    status_text = st.empty() 

    for path in local_files:
        file_name = os.path.basename(path)
        
        if file_name in existing_files:
            # File Ä‘Ã£ cÃ³ -> DÃ¹ng luÃ´n
            uploaded_refs.append(existing_files[file_name])
        else:
            # File chÆ°a cÃ³ -> Upload
            status_text.text(f"â¬†ï¸ Äang táº£i má»›i: {file_name}...")
            try:
                ref = genai.upload_file(path, mime_type="application/pdf")
                while ref.state.name == "PROCESSING":
                    time.sleep(1)
                    ref = genai.get_file(ref.name)
                uploaded_refs.append(ref)
                time.sleep(1) 
            except Exception as e:
                print(f"Lá»—i: {e}")

    status_text.empty()

    # Khá»Ÿi táº¡o Model
    system_instruction = """
    Báº¡n lÃ  ChuyÃªn gia Thuáº¿ - Káº¿ toÃ¡n - Háº£i quan cáº¥p cao táº¡i Viá»‡t Nam.
    Dá»±a trÃªn cÃ¡c vÄƒn báº£n luáº­t Ä‘Æ°á»£c cung cáº¥p, hÃ£y tÆ° váº¥n chÃ­nh xÃ¡c, trÃ­ch dáº«n Ä‘iá»u luáº­t.
    """
    
    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash", 
        system_instruction=system_instruction
    )
    
    return model, uploaded_refs

# --- 3. GIAO DIá»†N CHÃNH ---

# SIDEBAR: HIá»‚N THá»Š DANH SÃCH FILE (Äá»ƒ anh kiá»ƒm tra)
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063822.png", width=80)
    st.title("ğŸ—‚ï¸ Dá»¯ liá»‡u Ä‘Ã£ náº¡p")
    
    if st.button("ğŸ”„ Báº¥m vÃ o Ä‘Ã¢y Ä‘á»ƒ Náº¡p láº¡i Dá»¯ liá»‡u"):
        st.cache_resource.clear()
        st.rerun()
    
    st.divider()

# MAIN CONTENT
st.markdown('<div class="main-header">ğŸ›ï¸ PHÃ’NG KHÃM THUáº¾ AI</div>', unsafe_allow_html=True)

api_key = get_api_key()

if not api_key:
    api_key = st.text_input("Nháº­p API Key:", type="password")

if api_key:
    try:
        model, knowledge_refs = initialize_knowledge_base(api_key)
        
        if isinstance(model, str): 
            st.warning(model)
        else:
            # HIá»‚N THá»Š DANH SÃCH FILE RA SIDEBAR
            with st.sidebar:
                st.success(f"Äang káº¿t ná»‘i: {len(knowledge_refs)} vÄƒn báº£n")
                for ref in knowledge_refs:
                    st.caption(f"ğŸ“„ {ref.display_name}")

            # Chat Logic
            if "chat_session" not in st.session_state:
                history_setup = [{"role": "user", "parts": knowledge_refs + ["HÃ£y ghi nhá»› toÃ n bá»™ vÄƒn báº£n luáº­t nÃ y."]},
                                 {"role": "model", "parts": "ÄÃ£ tiáº¿p nháº­n dá»¯ liá»‡u."}]
                st.session_state.chat_session = model.start_chat(history=history_setup)
                st.session_state.messages = []

            for msg in st.session_state.messages:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])

            if prompt := st.chat_input("Nháº­p cÃ¢u há»i..."):
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    box = st.empty()
                    box.markdown("âš¡ *Äang tra cá»©u...*")
                    try:
                        response = st.session_state.chat_session.send_message(prompt)
                        box.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    except Exception as e:
                        box.error("Há»‡ thá»‘ng Ä‘ang báº­n. Vui lÃ²ng thá»­ láº¡i.")

    except Exception as e:
        st.error(f"Lá»—i: {e}")
