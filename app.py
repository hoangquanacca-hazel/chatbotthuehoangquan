import streamlit as st
import google.generativeai as genai
import os
import time

# --- 1. C·∫§U H√åNH TRANG (GIAO DI·ªÜN CHUY√äN NGHI·ªÜP) ---
st.set_page_config(
    page_title="H·ªá th·ªëng Chuy√™n gia Thu·∫ø AI",
    page_icon="‚öñÔ∏è",
    layout="centered", # D√πng centered cho gi·ªëng chat app mobile
    initial_sidebar_state="collapsed" # ·∫®n sidebar cho g·ªçn
)

# CSS ƒë·ªÉ ·∫©n c√°c th√†nh ph·∫ßn th·ª´a, l√†m ƒë·∫πp giao di·ªán
st.markdown("""
<style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stChatMessage {border-radius: 15px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);}
    .main-header {text-align: center; font-size: 28px; font-weight: 800; color: #1E88E5; margin-bottom: 20px;}
    .sub-header {text-align: center; font-size: 14px; color: #666; margin-bottom: 30px;}
</style>
""", unsafe_allow_html=True)

# --- 2. H√ÄM H·ªÜ TH·ªêNG (CORE SYSTEM) ---

def get_api_key():
    """L·∫•y API Key t·ª´ Secrets (∆Øu ti√™n) ho·∫∑c File local"""
    if "GOOGLE_API_KEY" in st.secrets:
        return st.secrets["GOOGLE_API_KEY"]
    return None

def get_local_pdf_files(folder_path="tailieu"):
    """Qu√©t th∆∞ m·ª•c tailieu"""
    if not os.path.exists(folder_path):
        return []
    return [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]

# üî• CACHE RESOURCE: Tr√°i tim c·ªßa h·ªá th·ªëng
# H√†m n√†y ch·ªâ ch·∫°y 1 l·∫ßn duy nh·∫•t khi Server kh·ªüi ƒë·ªông.
# N√≥ upload file v√† gi·ªØ k·∫øt n·ªëi trong b·ªô nh·ªõ RAM c·ªßa Server.
@st.cache_resource(show_spinner="ƒêang kh·ªüi t·∫°o h·ªá tri th·ª©c Thu·∫ø (L·∫ßn ƒë·∫ßu s·∫Ω m·∫•t kho·∫£ng 1 ph√∫t)...")
def initialize_knowledge_base(_api_key):
    genai.configure(api_key=_api_key)
    
    # 1. L·∫•y file t·ª´ ·ªï c·ª©ng server (do GitHub ƒë·∫©y sang)
    local_files = get_local_pdf_files()
    if not local_files:
        return None, "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu trong th∆∞ m·ª•c 'tailieu'."

    # 2. Ki·ªÉm tra file tr√™n Google (ƒë·ªÉ tr√°nh upload l·∫°i)
    uploaded_refs = []
    existing_files = {f.display_name: f for f in genai.list_files()}
    
    # Thanh ti·∫øn tr√¨nh ·∫©n (ch·ªâ hi·ªán log trong console server)
    print(f"B·∫Øt ƒë·∫ßu ƒë·ªìng b·ªô {len(local_files)} vƒÉn b·∫£n lu·∫≠t...")

    for path in local_files:
        file_name = os.path.basename(path)
        
        if file_name in existing_files:
            # File ƒë√£ c√≥ -> D√πng lu√¥n
            uploaded_refs.append(existing_files[file_name])
            print(f"   [OK] ƒê√£ c√≥: {file_name}")
        else:
            # File ch∆∞a c√≥ -> Upload
            print(f"   [UP] ƒêang t·∫£i: {file_name}...")
            try:
                ref = genai.upload_file(path, mime_type="application/pdf")
                # Ch·ªù file x·ª≠ l√Ω xong
                while ref.state.name == "PROCESSING":
                    time.sleep(1)
                    ref = genai.get_file(ref.name)
                uploaded_refs.append(ref)
                time.sleep(1) # Ngh·ªâ nh·∫π tr√°nh spam
            except Exception as e:
                print(f"   [ERR] L·ªói file {file_name}: {e}")

    # 3. Kh·ªüi t·∫°o Model v·ªõi d·ªØ li·ªáu ƒë√£ n·∫°p
    system_instruction = """
    B·∫°n l√† Chuy√™n gia Thu·∫ø - K·∫ø to√°n - H·∫£i quan c·∫•p cao t·∫°i Vi·ªát Nam (Tax Counsel).
    B·∫°n ƒëang s·ªü h·ªØu m·ªôt kho d·ªØ li·ªáu ph√°p lu·∫≠t kh·ªïng l·ªì ƒë∆∞·ª£c ƒë√≠nh k√®m.
    
    NHI·ªÜM V·ª§:
    - Gi·∫£i ƒë√°p th·∫Øc m·∫Øc d·ª±a tr√™n c√°c vƒÉn b·∫£n lu·∫≠t ƒë√£ h·ªçc.
    - Phong c√°ch: Chuy√™n nghi·ªáp, Ch√≠nh x√°c, Tr√≠ch d·∫´n ƒëi·ªÅu lu·∫≠t c·ª• th·ªÉ.
    - N·∫øu c√¢u h·ªèi n·∫±m ngo√†i ph·∫°m vi t√†i li·ªáu, h√£y d√πng ki·∫øn th·ª©c chung nh∆∞ng c·∫£nh b√°o ng∆∞·ªùi d√πng.
    """
    
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash", # D√πng b·∫£n Flash cho nhanh v√† b·ªô nh·ªõ l·ªõn
        system_instruction=system_instruction
    )
    
    return model, uploaded_refs

# --- 3. GIAO DI·ªÜN CH√çNH (MAIN APP) ---

# Ti√™u ƒë·ªÅ
st.markdown('<div class="main-header">üèõÔ∏è PH√íNG KH√ÅM THU·∫æ AI</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">H·ªá th·ªëng h·ªó tr·ª£ ph√°p l√Ω t·ª± ƒë·ªông d√†nh cho SME & H·ªô kinh doanh</div>', unsafe_allow_html=True)

# Ki·ªÉm tra API Key
api_key = get_api_key()
if not api_key:
    st.error("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh API Key. Vui l√≤ng th√™m v√†o Secrets.")
    st.stop()

# Kh·ªüi ƒë·ªông n√£o b·ªô (Ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu, c√°c l·∫ßn sau l·∫•y t·ª´ Cache -> Si√™u nhanh)
try:
    model, knowledge_refs = initialize_knowledge_base(api_key)
    
    if isinstance(model, str): # N·∫øu tr·∫£ v·ªÅ chu·ªói nghƒ©a l√† c√≥ l·ªói
        st.warning(model)
        st.stop()
        
    # Qu·∫£n l√Ω h·ªôi tho·∫°i
    if "chat_session" not in st.session_state:
        # N·∫°p l·ªãch s·ª≠ l·∫ßn ƒë·∫ßu g·ªìm to√†n b·ªô file lu·∫≠t
        history_setup = [{"role": "user", "parts": knowledge_refs + ["H√£y ghi nh·ªõ to√†n b·ªô vƒÉn b·∫£n lu·∫≠t n√†y ƒë·ªÉ t∆∞ v·∫•n."]},
                         {"role": "model", "parts": "T√¥i ƒë√£ ti·∫øp nh·∫≠n to√†n b·ªô c∆° s·ªü d·ªØ li·ªáu lu·∫≠t. S·∫µn s√†ng ph·ª•c v·ª•."}]
        st.session_state.chat_session = model.start_chat(history=history_setup)
        st.session_state.messages = [] # Ch·ªâ hi·ªÉn th·ªã ƒëo·∫°n chat m·ªõi, ·∫©n ƒëo·∫°n n·∫°p file ƒëi

except Exception as e:
    st.error(f"L·ªói kh·ªüi ƒë·ªông h·ªá th·ªëng: {e}")
    st.stop()

# Hi·ªÉn th·ªã h·ªôi tho·∫°i
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# √î nh·∫≠p li·ªáu (N·∫±m d∆∞·ªõi c√πng)
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n (V√≠ d·ª•: Thu·∫ø kho√°n nƒÉm 2025 t√≠nh th·∫ø n√†o?)..."):
    # Hi·ªán c√¢u h·ªèi
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # X·ª≠ l√Ω tr·∫£ l·ªùi
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("‚ö° *ƒêang tra c·ª©u d·ªØ li·ªáu...*")
        try:
            response = st.session_state.chat_session.send_message(prompt)
            message_placeholder.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            message_placeholder.error("H·ªá th·ªëng ƒëang qu√° t·∫£i, vui l√≤ng th·ª≠ l·∫°i sau gi√¢y l√°t.")
