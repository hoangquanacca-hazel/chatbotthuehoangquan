import streamlit as st
import google.generativeai as genai
import os
import time

# --- 1. C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Ph√≤ng kh√°m Thu·∫ø AI (Pro)", page_icon="üè•", layout="wide", initial_sidebar_state="expanded")

st.markdown("""
<style>
    .main-header {text-align: center; font-size: 26px; font-weight: bold; color: #d32f2f; margin-bottom: 20px;}
    .error-msg {background-color: #ffebee; padding: 10px; border-radius: 5px; color: #b71c1c; border: 1px solid #ffcdd2;}
</style>
""", unsafe_allow_html=True)

# --- 2. H√ÄM H·ªÜ TH·ªêNG ---
def get_api_key():
    if "GOOGLE_API_KEY" in st.secrets: return st.secrets["GOOGLE_API_KEY"]
    try: import toml; return toml.load(".streamlit/secrets.toml")["GOOGLE_API_KEY"]
    except: return None

def get_local_pdf_files(folder_path="tailieu"):
    if not os.path.exists(folder_path): return []
    return [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]

@st.cache_resource(show_spinner="ƒêang k·∫øt n·ªëi d·ªØ li·ªáu l·ªõn...")
def initialize_knowledge_base(_api_key):
    genai.configure(api_key=_api_key)
    local_files = get_local_pdf_files()
    if not local_files: return None, "Th∆∞ m·ª•c 'tailieu' tr·ªëng."

    try: remote_files = {f.display_name: f for f in genai.list_files()}
    except: remote_files = {}

    final_refs = []
    print(f"--- B·∫ÆT ƒê·∫¶U N·∫†P {len(local_files)} FILE ---")

    for path in local_files:
        name = os.path.basename(path)
        if name in remote_files:
            final_refs.append(remote_files[name])
        else:
            print(f"‚¨ÜÔ∏è T·∫£i l√™n: {name}")
            try:
                ref = genai.upload_file(path, mime_type="application/pdf")
                # Ch·ªù x·ª≠ l√Ω (TƒÉng timeout l√™n 90s cho file n·∫∑ng)
                start_wait = time.time()
                while ref.state.name == "PROCESSING":
                    if time.time() - start_wait > 90: break
                    time.sleep(2)
                    ref = genai.get_file(ref.name)
                if ref.state.name == "ACTIVE": final_refs.append(ref)
                time.sleep(2)
            except Exception as e: print(f"L·ªói file {name}: {e}")

    # C·∫•u h√¨nh Model PRO (B·ªô nh·ªõ 2 tri·ªáu token) & T·∫Øt Safety
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    
    # D√πng b·∫£n 1.5 PRO ƒë·ªÉ ch·ª©a h·∫øt 23 file
    model = genai.GenerativeModel(
        model_name="gemini-1.5-pro", 
        safety_settings=safety_settings,
        system_instruction="B·∫°n l√† Chuy√™n gia Thu·∫ø. Tr·∫£ l·ªùi d·ª±a tr√™n vƒÉn b·∫£n ƒë√≠nh k√®m."
    )
    return model, final_refs

# --- 3. GIAO DI·ªÜN CH√çNH ---
st.markdown('<div class="main-header">üè• PH√íNG KH√ÅM THU·∫æ AI (DEBUG)</div>', unsafe_allow_html=True)

api_key = get_api_key()
if not api_key: st.stop()

try:
    model, refs = initialize_knowledge_base(api_key)
    
    with st.sidebar:
        st.success(f"ƒê√£ k·∫øt n·ªëi: {len(refs)} vƒÉn b·∫£n")
        if st.button("üîÑ Reset D·ªØ li·ªáu"):
            st.cache_resource.clear()
            st.rerun()

    if "chat" not in st.session_state:
        history = [{"role": "user", "parts": refs + ["H·ªçc thu·ªôc."]}, {"role": "model", "parts": "OK."}]
        st.session_state.chat = model.start_chat(history=history)
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)

        with st.chat_message("assistant"):
            msg_box = st.empty()
            try:
                # In ra ƒë·ªÉ bi·∫øt ƒëang x·ª≠ l√Ω
                msg_box.write("‚è≥ ƒêang suy nghƒ© (Model Pro m·∫•t kho·∫£ng 5-10s)...")
                response = st.session_state.chat.send_message(prompt, stream=True)
                full_text = ""
                for chunk in response:
                    if chunk.text:
                        full_text += chunk.text
                        msg_box.markdown(full_text + "‚ñå")
                msg_box.markdown(full_text)
                st.session_state.messages.append({"role": "assistant", "content": full_text})
                
            except Exception as e:
                # HI·ªÜN L·ªñI CHI TI·∫æT RA M√ÄN H√åNH
                error_text = str(e)
                st.markdown(f'<div class="error-msg">‚ùå <b>L·ªñI H·ªÜ TH·ªêNG:</b><br>{error_text}</div>', unsafe_allow_html=True)
                
                # Ph√¢n t√≠ch l·ªói gi√∫p anh
                if "429" in error_text:
                    st.info("üí° Nguy√™n nh√¢n: G√≥i Free c·ªßa b·∫£n Pro ch·ªâ cho ph√©p 2 c√¢u h·ªèi/ph√∫t. Anh h·ªèi nhanh qu√° n√™n b·ªã ch·∫∑n.")
                elif "400" in error_text:
                    st.info("üí° Nguy√™n nh√¢n: D·ªØ li·ªáu qu√° l·ªõn ho·∫∑c file l·ªói.")

except Exception as e:
    st.error(f"L·ªói kh·ªüi ƒë·ªông: {e}")


